# -*- coding: utf-8 -*-
"""Torch_Traffic_Signs_Basic_Template_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XR0l6YQ3w_r8-PtVHm59-No94ptQBKxT

# Basic CNN for traffic sign recognition
## ADL 2022

This notebook provides a template for a small CNN for the German Traffic Sign Recognition Benchmark. The data is described in:

Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. Man vs. Computer: Benchmarking Machine Learning Algorithms for Traffic Sign Recognition. *Neural Networks* **32**, pp. 323-332, 2012

This notebook is a template, without modification the model does not even come close to the state-of-the-art. 

Please [contact Stefan](mailto:sommer@di.ku.dk) if you have suggestions for improving the notebook.

The original version of the notebook was written by [Christian Igel](mailto:igel@di.ku.dk). It has been slightly modified by [Stefan Sommer](mailto:sommer@di.ku.dk) and the TAs of ADL 2022.

Do the imports first:
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import matplotlib.pyplot as plt
import numpy as np

import torch 
import torch.optim as optim

import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms
from torch.utils.data.dataset import Dataset
from torchvision.datasets.utils import download_url, extract_archive

from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter()
# Load the TensorBoard notebook extension
# %load_ext tensorboard

"""Check if a GPU is available:"""

gpu = torch.cuda.is_available()
device = torch.device("cuda:0" if gpu else "cpu")
print("device:", device)

"""The GTSRB data wrapped in a `Dataset`:"""

class GTSRBTrafficSigns(Dataset):
  def __init__(self, root = './', url = 'https://sid.erda.dk/share_redirect/EB0rrpZwuI', filename='EB0rrpZwuI.zip', train=True, force_download=False): 
    self.img_height  = 32  
    self.img_width   = self.img_height
    self.img_height_crop = 28  
    self.img_width_crop  = self.img_height_crop

    self.train = train
    archive = os.path.join(root, filename)

    if self.train:
      self.data_folder = os.path.join(root, 'GTSRB/train')
    else:
      self.data_folder = os.path.join(root, 'GTSRB/test')

    if (not os.path.exists(self.data_folder)) or force_download:
       download_url(url, root, filename)
       extract_archive(archive, root, False)
    else:
      print('Using existing', self.data_folder)

    self.dataset_train = datasets.ImageFolder(self.data_folder)

  def __getitem__(self, index):
      image, label = self.dataset_train.__getitem__(index)
      image = transforms.Resize((self.img_width,self.img_height))(image)
      
      if self.train:
        image = transforms.RandomAffine((-5,5))(image)
        image = transforms.RandomCrop((self.img_width_crop, self.img_height_crop))(image)
        image = transforms.ColorJitter(0.8, contrast = 0.4)(image)
        if label in [11, 12, 13, 17, 18, 26, 30, 35]:
          image = transforms.RandomHorizontalFlip(p=0.5)(image)
      else:
        image = transforms.CenterCrop((self.img_width_crop, self.img_height_crop))(image)

      image = transforms.ToTensor()(image)

      return image, label

  def __len__(self):
      return self.dataset_train.__len__()

dataset_train = GTSRBTrafficSigns()

"""Define the data loader for training:"""

batch_size = 128
generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)

"""Let's visualize some input images. This visualization is very important, among others to verify that the data augmentation works as expected."""

# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')
    plt.show()


# get some random training images
dataiter = iter(generator_train)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))

"""Let's look at some images in the batch with their label:"""

for i in range(0,batch_size,10):
  imshow(images[i])
  print(labels[i].item(), "\n\n")

"""Define the neural network:"""

class Net(nn.Module):
    def __init__(self, img_size=28):
        super(Net, self).__init__()
        # Add code here .... (see e.g. 'Switch to CNN' at https://pytorch.org/tutorials/beginner/nn_tutorial.html)
        self.conv1 = nn.Conv2d(3, 64, kernel_size =(5, 5), stride =(1, 1))
        self.conv1_batch=nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d (64, 32, kernel_size =(5, 5), stride =(1, 1))
        self.conv2_batch=nn.BatchNorm2d(32)

        self.pool1 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)

        self.conv3 = nn.Conv2d (32, 32, kernel_size =(3, 3), stride =(1, 1))
        self.conv3_batch=nn.BatchNorm2d(32)

        self.pool2 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.fc3 = nn.Linear(in_features =512, out_features =43, bias=True)

    def forward(self, x):
        x = F.elu(self.conv1(x))
        x = self.pool1(F.elu(self.conv2(x)))
        x = self.pool2(F.elu(self.conv3(x)))
        x = torch.flatten(x, start_dim=1)
        x = self.fc3(x)
        return x

"""Instantiate the neural network and potentially move it to GPU:"""

net = Net()
if(gpu):
  net.to(device)
print(net)

"""Define loss and optimization algorithm:"""

criterion = nn.CrossEntropyLoss()
## switch optimizer
optimizer = optim.Adam(net.parameters(), lr=0.001, eps=0.1)

"""These lines can be used to continue training:"""

cont = False
if cont:
  net.load_state_dict(torch.load('traffic_simple'))

"""Do the training:"""

no_epochs = 200
for epoch in range(no_epochs):  # Loop over the dataset multiple times
    epoch_loss = running_loss = 0.0
    for i, data in enumerate(generator_train, 0):
        # Get the inputs; data is a list of [inputs, labels]
        if (gpu):
          inputs, labels = data[0].to(device), data[1].to(device)
        else:
          inputs, labels = data
        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # Print statistics
        reporting_interval = 100
        epoch_loss += loss.item()
        running_loss += loss.item()
        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches
            # report_loss = running_loss / reproint
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / reporting_interval))
            running_loss = 0.0
    
    # Log to tensorboard
    writer.add_scalar("Loss/train", epoch_loss/(i+1.), epoch)


print('Finished Training')
writer.flush()

"""Evaluate on test set:"""

dataset_test = GTSRBTrafficSigns(train=False)
generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)
# With Batch normalization
#temp_net = net.eval() 
# Without Batch normalization
temp_net = net
correct = 0
total = 0
with torch.no_grad():
    for data in generator_test:
        if (gpu):
          images, labels = data[0].to(device), data[1].to(device)
        else:
          images, labels = data
        outputs = temp_net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))

"""Save network:"""

torch.save(temp_net.state_dict(), 'traffic_simple')

"""Visualize training with tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir runs

# Commented out IPython magic to ensure Python compatibility.
dataset_train = GTSRBTrafficSigns()
batch_size = 128
generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)
# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')
    plt.show()


# get some random training images
dataiter = iter(generator_train)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))



class Net(nn.Module):
    def __init__(self, img_size=28):
        super(Net, self).__init__()
        # Add code here .... (see e.g. 'Switch to CNN' at https://pytorch.org/tutorials/beginner/nn_tutorial.html)
        self.conv1 = nn.Conv2d(3, 64, kernel_size =(5, 5), stride =(1, 1))
        self.conv1_batch=nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d (64, 32, kernel_size =(5, 5), stride =(1, 1))
        self.conv2_batch=nn.BatchNorm2d(32)

        self.pool1 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)

        self.conv3 = nn.Conv2d (32, 32, kernel_size =(3, 3), stride =(1, 1))
        self.conv3_batch=nn.BatchNorm2d(32)

        self.pool2 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.fc3 = nn.Linear(in_features =512, out_features =43, bias=True)



    def forward(self, x):
        x = F.elu(self.conv1_batch(self.conv1(x)))
        x = self.pool1(F.elu(self.conv2_batch(self.conv2(x))))
        x = self.pool2(F.elu(self.conv3_batch(self.conv3(x))))
        x = torch.flatten(x, start_dim=1)
        x = self.fc3(x)
        return x

net = Net()
if(gpu):
  net.to(device)
print(net)


criterion = nn.CrossEntropyLoss()
## switch optimizer
optimizer = optim.Adam(net.parameters(), lr=0.001, eps=0.1)

cont = False
if cont:
  net.load_state_dict(torch.load('traffic_simple'))


no_epochs = 200
for epoch in range(no_epochs):  # Loop over the dataset multiple times
    epoch_loss = running_loss = 0.0
    for i, data in enumerate(generator_train, 0):
        # Get the inputs; data is a list of [inputs, labels]
        if (gpu):
          inputs, labels = data[0].to(device), data[1].to(device)
        else:
          inputs, labels = data
        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # Print statistics
        reporting_interval = 100
        epoch_loss += loss.item()
        running_loss += loss.item()
        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches
            # report_loss = running_loss / reproint
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / reporting_interval))
            running_loss = 0.0
    
    # Log to tensorboard
    writer.add_scalar("Loss/train", epoch_loss/(i+1.), epoch)


print('Finished Training')
writer.flush()

dataset_test = GTSRBTrafficSigns(train=False)
generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)
# With Batch normalization
#temp_net = net.eval() 
# Without Batch normalization
temp_net = net
correct = 0
total = 0
with torch.no_grad():
    for data in generator_test:
        if (gpu):
          images, labels = data[0].to(device), data[1].to(device)
        else:
          images, labels = data
        outputs = temp_net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))

torch.save(temp_net.state_dict(), 'traffic_simple')

# %tensorboard --logdir runs

# Commented out IPython magic to ensure Python compatibility.
dataset_train = GTSRBTrafficSigns()
batch_size = 128
generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)
# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')
    plt.show()


# get some random training images
dataiter = iter(generator_train)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))



class Net(nn.Module):
    def __init__(self, img_size=28):
        super(Net, self).__init__()
        # Add code here .... (see e.g. 'Switch to CNN' at https://pytorch.org/tutorials/beginner/nn_tutorial.html)
        self.conv1 = nn.Conv2d(3, 64, kernel_size =(5, 5), stride =(1, 1))
        self.conv1_batch=nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d (64, 32, kernel_size =(5, 5), stride =(1, 1))
        self.conv2_batch=nn.BatchNorm2d(32)

        self.pool1 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)

        self.conv3 = nn.Conv2d (32, 32, kernel_size =(3, 3), stride =(1, 1))
        self.conv3_batch=nn.BatchNorm2d(32)

        self.pool2 = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)
        self.fc3 = nn.Linear(in_features =512, out_features =43, bias=True)



    def forward(self, x):
        x = F.elu(self.conv1(self.conv1(x)))
        x = self.pool1(F.elu(self.conv2(self.conv2(x))))
        x = self.pool2(F.elu(self.conv3(self.conv3(x))))
        x = torch.flatten(x, start_dim=1)
        x = self.fc3(x)
        return x

net = Net()
if(gpu):
  net.to(device)
print(net)

criterion = nn.CrossEntropyLoss()
## switch optimizer
optimizer = optim.SGD(net.parameters(), lr=0.001)

cont = False
if cont:
  net.load_state_dict(torch.load('traffic_simple'))


no_epochs = 200
for epoch in range(no_epochs):  # Loop over the dataset multiple times
    epoch_loss = running_loss = 0.0
    for i, data in enumerate(generator_train, 0):
        # Get the inputs; data is a list of [inputs, labels]
        if (gpu):
          inputs, labels = data[0].to(device), data[1].to(device)
        else:
          inputs, labels = data
        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # Print statistics
        reporting_interval = 100
        epoch_loss += loss.item()
        running_loss += loss.item()
        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches
            # report_loss = running_loss / reproint
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / reporting_interval))
            running_loss = 0.0
    
    # Log to tensorboard
    writer.add_scalar("Loss/train", epoch_loss/(i+1.), epoch)


print('Finished Training')
writer.flush()

dataset_test = GTSRBTrafficSigns(train=False)
generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)
# With Batch normalization
#temp_net = net.eval() 
# Without Batch normalization
temp_net = net
correct = 0
total = 0
with torch.no_grad():
    for data in generator_test:
        if (gpu):
          images, labels = data[0].to(device), data[1].to(device)
        else:
          images, labels = data
        outputs = temp_net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))

torch.save(temp_net.state_dict(), 'traffic_simple')

# %tensorboard --logdir runs

pip install -q pytorch_lightning lightning-bolts
import os
import matplotlib.pyplot as plt
import numpy as np

import torch
from torch import nn as nn
from torch.nn import functional as F
from torchvision.datasets.utils import download_url
import torchmetrics
from pprint import pformat
from skimage.transform import resize
from pathlib import Path
from glob import glob
from matplotlib.pyplot import imread
from collections import defaultdict

try:
    from google.colab import drive
    drive.mount('/content/gdrive/')
    os.chdir('gdrive/MyDrive/ADL2022')
except:
    print('Google drive not mounted')


# GPU support?
gpu = torch.cuda.is_available()
device = torch.device("cuda:0" if gpu else "cpu")
print("device:", device)

from pl_bolts.models.vision import UNet


class ModUNet(nn.Module):
    """
    Paper: `U-Net: Convolutional Networks for Biomedical Image Segmentation
    <https://arxiv.org/abs/1505.04597>`_

    Paper authors: Olaf Ronneberger, Philipp Fischer, Thomas Brox

    Implemented by:

        - `Annika Brundyn <https://github.com/annikabrundyn>`_
        - `Akshay Kulkarni <https://github.com/akshaykvnit>`_

    Args:
        num_classes: Number of output classes required
        input_channels: Number of channels in input images (default 3)
        num_layers: Number of layers in each side of U-net (default 5)
        features_start: Number of features in first layer (default 64)
        bilinear: Whether to use bilinear interpolation or transposed convolutions (default) for upsampling.
    """

    def __init__(
        self,
        num_classes: int,
        input_channels: int = 3,
        num_layers: int = 5,
        features_start: int = 64,
        bilinear: bool = False,
    ):

        if num_layers < 1:
            raise ValueError(f"num_layers = {num_layers}, expected: num_layers > 0")

        super().__init__()
        self.num_layers = num_layers

        layers = [DoubleConv(input_channels, features_start)]

        feats = features_start
        for _ in range(num_layers - 1):
            layers.append(Down(feats, feats * 2))
            feats *= 2

        for _ in range(num_layers - 1):
            layers.append(Up(feats, feats // 2, bilinear))
            feats //= 2

        layers.append(nn.Conv2d(feats, num_classes, kernel_size=1))

        self.layers = nn.ModuleList(layers)

    def forward(self, x):
        xi = [self.layers[0](x)]
        # Down path
        for layer in self.layers[1 : self.num_layers]:
            xi.append(layer(xi[-1]))
        # Up path
        for i, layer in enumerate(self.layers[self.num_layers : -1]):
            xi[-1] = layer(xi[-1], xi[-2 - i])
        return self.layers[-1](xi[-1])

data_root='./datasets'
data_npz='lung_field_dataset.npz'
data_fn = os.path.join(data_root, "lung_field_dataset.npz")
force_download = False

if (not os.path.exists(data_fn)) or force_download:
  download_url("https://sid.erda.dk/share_redirect/gCTc6o3KAh", data_root, data_npz)
else:
  print('Using existing', data_fn)


def plot_image_with_segmentation(image, segmentation, ax=None):
    """
    Plots an image with overlayed segmentation mask
    
    Returns: plt.fig and ax objects
    """
    if ax is None:
        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111)
        ax.axis("off")
    
    ax.imshow(image.squeeze(), cmap="gray")
    mask = np.ma.masked_where(segmentation == 0, segmentation)
    ax.imshow(mask.squeeze(), cmap="Set1", alpha=0.5)
    return plt.gcf(), ax


def load_npz_dataset(path, keys=('x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test')):
    archive = np.load(path)
    return [archive.get(key) for key in keys]


from google.colab import drive
drive.mount('/content/drive')

# Load train/val/test data
data = load_npz_dataset("/content/drive/MyDrive/lung_field_dataset.npz")
x_train, y_train, x_val, y_val, x_test, y_test = data
# Bring images into PyTorch format
x_train = np.moveaxis(x_train, 3, 1)
y_train = np.moveaxis(y_train, 3, 1)
x_val = np.moveaxis(x_val, 3, 1)
y_val = np.moveaxis(y_val, 3, 1)
x_test = np.moveaxis(x_test, 3, 1)
y_test = np.moveaxis(y_test, 3, 1)

print("x train:", x_train.shape)
print("y train:", y_train.shape)
print("x val: ", x_val.shape)
print("y val: ", y_val.shape)
print("x test:", x_test.shape)
print("y test:", y_test.shape)

# Plot an example
fig, ax = plot_image_with_segmentation(x_train[0], y_train[0])
plt.show()

def as_torch_dataset(x_arr, y_arr):
    """
    Takes two numpy arrays of data points and labels (x_arr and y_arr, respectively) and
    returns a torch TensorDataset object.
    
    Returns: torch.utils.data.TensorDataset
    """
    dataset = torch.utils.data.TensorDataset(
        torch.FloatTensor(x_arr), 
        torch.LongTensor(y_arr)
    )
    return dataset

# Init torch datasets
train_dataset = as_torch_dataset(x_train, y_train.squeeze(1))  # remove dummy channel dim
val_dataset = as_torch_dataset(x_val, y_val.squeeze(1))
test_dataset = as_torch_dataset(x_test, y_test.squeeze(1))

# Init dataloaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

def evaluate_model(model, data_loader, metrics_dict, reduction=True, device=device):
    """
    Evaluate a model 'model' on all batches of a torch DataLoader 'data_loader'.
    On each batch, compute all metric functions stored in dictionary 'metrics_dict'.
    
    Returns: dict of metric_name: (list of batch-wise metrics if reduction == False, else single scalar)
    """
    
    # defaultdict(list) returns a dictionary-like object with default_factory list. 
    # When a new key is encountered, an entry is automatically created of type default_factory. 
    metrics = defaultdict(list)
    with torch.no_grad():
        for batch_x, batch_y in data_loader:
            # Predict on batch
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            logits = model(batch_x)
            
            # Compute all metrics
            for metric_name, metric_func in metrics_dict.items():
                value = metric_func(logits.cpu(), batch_y.cpu()).item() #.cpu().numpy()
                metrics[metric_name].append(value)
    
    if reduction == True:
        # Return mean values
        return {key: np.mean(value) for key, value in metrics.items()}
    else:
        return metrics

def run_one_epoch(model, loss, optimizer, train_loader, val_loader, n_epochs, metrics_dict, device=device):
    """
    Run 1 epoch of training
    Changes to model parameters and optimizer occour internally (state updates)
    Returns:
        two dictionaries, training and a validation metrics
    """
    train_losses = []
    for i, (batch_x, batch_y) in enumerate(train_loader):
        # Zero out stored gradients for all parameters
        batch_x = batch_x.to(device)
        batch_y = batch_y.to(device)
        optimizer.zero_grad()
        
        print(f"   -- Batch {i+1}/{len(train_loader)}", end=" / ")
        # Predict on batch
        logits = model(batch_x)
        
        # Compute loss function
        loss_tensor = loss(logits, batch_y)
        loss_scalar = loss_tensor.detach().cpu().numpy()
        train_losses.append(loss_scalar)
        print("Loss: ", loss_scalar)
        
        # Backprop and step
        loss_tensor.backward()
        optimizer.step()
        
    # Run validation
    print("   Validation running...")
    val_metrics = evaluate_model(
        model=model, 
        data_loader=val_loader,
        metrics_dict=metrics_dict
    )
    # Return loss and metrics as dicts
    return {"loss": np.mean(train_losses)}, val_metrics


def merge_list_of_dicts(list_of_dicts):
    """
    Takes a list of dictionaries and merges them into a single dictionary pointing to lists
    
    E.g. [{"loss": 5}, {"loss": 3}, {"loss": -2, "F1": 0.5}] --> {"loss": [5, 3, -2], "F1": [0.5]}
    
    Returns: dict
    """
    merged = defaultdict(list)
    for dict_ in list_of_dicts:
        for value, key in dict_.items():
            merged[value].append(key)
    return merged


def training_loop(model, loss, optimizer, train_loader, val_loader, n_epochs, init_epoch=None, metrics_dict=None, save_path=None):
    """
    Run training of a model given a loss function, optimizer and a set of training and validation data.
    Supports computing additional metrics on the validation set (only) via the metrics_dict param.
    Specify save_path to store the model at each epoch.
    
    Returns: 
        Two lists of metric dictionaries for each epoch for training and validation, specifically
    """
    train_history, val_history = [], []
    
    metrics_with_loss = {"loss": loss}
    if metrics_dict is not None:
        metrics_with_loss.update(metrics_dict)
    
    if init_epoch == None:
        init_epoch = 0
    try:
        for i in range(init_epoch, n_epochs):
            print(f"Epoch {i+1}/{n_epochs}")
            train_metrics, val_metrics = run_one_epoch(
                model=model, 
                loss=loss, 
                optimizer=optimizer, 
                train_loader=train_loader, 
                val_loader=val_loader, 
                n_epochs=n_epochs,
                metrics_dict=metrics_with_loss
            )
            print("   Mean epoch metrics:")
            print(f"   Training:   {pformat(train_metrics)}")
            print(f"   Validation: {pformat(val_metrics)}")
            train_history.append(train_metrics), val_history.append(val_metrics)
            
            if save_path:
                save_path_epoch = f"epoch_{i+1}_{save_path}"
                print(f"   Saving to: {save_path_epoch}")
                save_model(model, save_path_epoch, optimizer)
    except KeyboardInterrupt:
        print("Training stopped.")
        pass
    
    # Merge list of training and validation dicts into single dicts    
    return merge_list_of_dicts(train_history), merge_list_of_dicts(val_history)

def plot_histories(train_history=None, val_history=None, label="Loss"):
    """
    Takes a list of training and/or validation metrics and plots them
    Returns: plt.figure and ax objects
    """
    if not train_history and not val_history:
        raise ValueError("Must specify at least one of 'train_histories' and 'val_histories'")
    fig = plt.figure(figsize=(5, 3))
    ax = fig.add_subplot(111)
    
    epochs = np.arange(len(train_history or val_history))
    if train_history:
        ax.plot(epochs, train_history, label="Training", color="black")
    if val_history:
        ax.plot(epochs, val_history, label="Validation", color="darkred")
    
    ax.set_xlabel("Epoch")
    ax.set_ylabel(label)
    ax.legend(loc=0)
    
    return fig, ax

def save_model(model, path, optimizer=None):
    """
    Saves the state_dict of a torch model and optional optimizer to 'path'
    Returns: None
    """
    state = {"model": model.state_dict()}
    if optimizer is not None:
        state["optimizer"] = optimizer.state_dict()
    torch.save(state, path)


def load_model(model, path, optimizer=None):
    """
    Loads the state_dict of a torch model and optional optimizer from 'path'
    Returns: None
    """
    state = torch.load(path)
    model.load_state_dict(state["model"])
    if optimizer is not None:
        optimizer.load_state_dict(state["optimizer"])

class DoubleConv(nn.Module):
    """[ Conv2d => BatchNorm (optional) => ReLU ] x 2."""

    def __init__(self, in_ch: int, out_ch: int):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ELU(inplace=True),
            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ELU(inplace=True),
        )

    def forward(self, x):
        return self.net(x)


class Down(nn.Module):
    """Downscale with MaxPool => DoubleConvolution block."""

    def __init__(self, in_ch: int, out_ch: int):
        super().__init__()
        self.net = nn.Sequential(nn.MaxPool2d(kernel_size=2, stride=2), DoubleConv(in_ch, out_ch))

    def forward(self, x):
        return self.net(x)


class Up(nn.Module):
    """Upsampling (by either bilinear interpolation or transpose convolutions) followed by concatenation of feature
    map from contracting path, followed by DoubleConv."""

    def __init__(self, in_ch: int, out_ch: int, bilinear: bool = False):
        super().__init__()
        self.upsample = None
        if bilinear:
            self.upsample = nn.Sequential(
                nn.Upsample(scale_factor=2, mode="nearest", align_corners=True),
                nn.Conv2d(in_ch, in_ch // 2, kernel_size=1),
            )
        else:
            self.upsample = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)

        self.conv = DoubleConv(in_ch, out_ch)

    def forward(self, x1, x2):
        x1 = self.upsample(x1)

        # Pad x1 to the size of x2
        diff_h = x2.shape[2] - x1.shape[2]
        diff_w = x2.shape[3] - x1.shape[3]

        x1 = F.pad(x1, [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2])

        # Concatenate along the channels axis
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


# Init U-Net model
model = ModUNet(
    num_classes=2, 
    input_channels=1, 
    num_layers=4, 
    features_start=16,
)

model.to(device)

# Define optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

# Specify integer, starting at 1
init_epoch = None
if init_epoch != None:
    load_model(model, f"epoch_{init_epoch}_model.ckpt", optimizer)


# Define loss and metrics
loss = torch.nn.CrossEntropyLoss(reduction="mean")
metrics = {"f1": torchmetrics.classification.F1Score(num_classes=2, average="macro", mdmc_average="samplewise")}

# Run training
train_history, val_history = training_loop(
    model=model,
    loss=loss, 
    optimizer=optimizer, 
    train_loader=train_loader, 
    val_loader=val_loader,
    init_epoch=init_epoch,
    n_epochs=100,
    metrics_dict=metrics,
    save_path="model.ckpt"
)

plot_histories(train_history['loss'], val_history['loss'], label="Loss")
plot_histories(train_history=None, val_history=val_history['f1'], label="F1 Score")
plt.show()


# Predict on a test image
x_test, y_test = test_dataset[0]
if gpu:
  x_test = x_test.to(device)
  y_test = y_test.to(device)
pred = model(x_test.view(1, 1, x_test.shape[1], x_test.shape[2])).argmax(1).cpu().numpy()

# Plot the result
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 15))
ax1.set_title("True mask")
ax2.set_title("Predicted mask")

plot_image_with_segmentation(x_test.cpu(), y_test.cpu(), ax=ax1)
plot_image_with_segmentation(x_test.cpu(), pred, ax=ax2)

plt.show()

# OBS: Returns batch-wise metrics, but test_loader has batch_size = 1
f1_test_scores = evaluate_model(model, test_loader, metrics, reduction=False)["f1"]

print("Test cases:", len(f1_test_scores))
print("Mean F1:   ", np.mean(f1_test_scores))
print("STD  F1:   ", np.std(f1_test_scores))
print("Min. F1:   ", np.min(f1_test_scores))